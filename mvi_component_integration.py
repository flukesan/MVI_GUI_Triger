"""
MVI Component Integration
Integration ‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á MVI Detection ‡∏Å‡∏±‡∏ö Component Definition

Features:
- ‡∏£‡∏±‡∏ö detection results ‡∏à‡∏≤‡∏Å MVI
- Match detected objects ‡∏Å‡∏±‡∏ö expected positions
- ‡∏£‡∏∞‡∏ö‡∏∏‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡∏ó‡∏µ‡πà‡∏´‡∏≤‡∏¢‡πÑ‡∏î‡πâ‡πÄ‡∏à‡∏≤‡∏∞‡∏à‡∏á
- ‡∏™‡∏£‡πâ‡∏≤‡∏á annotated images with missing highlights
- ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ú‡∏•‡∏•‡∏á database
"""

import cv2
import numpy as np
from typing import List, Dict, Optional, Tuple
import json
from datetime import datetime


class MVIComponentIntegration:
    """Integration ‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á MVI Detection ‡∏Å‡∏±‡∏ö Component Definition"""

    def __init__(self, component_definition_manager):
        """
        Args:
            component_definition_manager: ComponentDefinitionManager instance
        """
        self.comp_manager = component_definition_manager

    def process_mvi_result(self,
                          image: np.ndarray,
                          mvi_detections: List[Dict],
                          product_id: int,
                          verbose: bool = False) -> Dict:
        """
        ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏• MVI detection results + Component Definition

        Args:
            image: ‡∏†‡∏≤‡∏û‡∏à‡∏≤‡∏Å MVI (numpy array)
            mvi_detections: [
                {
                    "class": "pig",
                    "confidence": 0.94,
                    "bbox": {"x": 178, "y": 180, "width": 182, "height": 268}
                },
                {
                    "class": "monk",
                    "confidence": 0.98,
                    "bbox": {"x": 342, "y": 180, "width": 176, "height": 288}
                },
                ...
            ]
            product_id: ID ‡∏Ç‡∏≠‡∏á product
            verbose: ‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° debug

        Returns:
            Dict {
                "status": "PASS" or "FAIL",
                "reason": str,
                "found": int,
                "total": int,
                "found_percentage": float,
                "missing_components": [str],
                "missing_positions": [str],
                "component_results": [Dict],
                "annotated_image": numpy array
            }
        """

        if verbose:
            print(f"\n{'='*60}")
            print(f"üîç MVI Component Integration")
            print(f"{'='*60}")

        # 1. ‡πÇ‡∏´‡∏•‡∏î expected components
        expected_components = self.comp_manager.get_product_components(product_id)

        if not expected_components:
            return {
                "status": "ERROR",
                "reason": "No component definitions found for this product",
                "found": 0,
                "total": 0,
                "found_percentage": 0.0,
                "missing_components": [],
                "missing_positions": [],
                "component_results": [],
                "annotated_image": image
            }

        if verbose:
            print(f"Expected components: {len(expected_components)}")
            print(f"MVI detections: {len(mvi_detections)}")

        # 2. Match detected objects ‡∏Å‡∏±‡∏ö expected positions
        matching_results = self._match_components(
            expected_components,
            mvi_detections,
            verbose=verbose
        )

        # 3. ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏ú‡∏•
        analysis = self._analyze_results(
            matching_results,
            expected_components,
            verbose=verbose
        )

        # 4. ‡∏™‡∏£‡πâ‡∏≤‡∏á annotated image
        annotated_image = self._draw_annotations(
            image.copy(),
            matching_results,
            expected_components
        )

        if verbose:
            print(f"\n{'='*60}")
            print(f"Result: {analysis['status']}")
            print(f"Reason: {analysis['reason']}")
            print(f"Found: {analysis['found_count']}/{analysis['total_count']}")
            print(f"{'='*60}\n")

        return {
            "status": analysis["status"],
            "reason": analysis["reason"],
            "found": analysis["found_count"],
            "total": analysis["total_count"],
            "found_percentage": analysis["found_percentage"],
            "missing_components": analysis["missing_components"],
            "missing_positions": analysis["missing_positions"],
            "component_results": matching_results,
            "annotated_image": annotated_image
        }

    def _match_components(self,
                         expected_components: List[Dict],
                         mvi_detections: List[Dict],
                         verbose: bool = False) -> List[Dict]:
        """
        ‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö expected vs detected

        ‚ö†Ô∏è ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç: ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Å‡∏≤‡∏£ track detection ‡∏ó‡∏µ‡πà match ‡πÅ‡∏•‡πâ‡∏ß
        ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô detection ‡∏ï‡∏±‡∏ß‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏ñ‡∏π‡∏Å match ‡∏Å‡∏±‡∏ö expected ‡∏´‡∏•‡∏≤‡∏¢‡∏ï‡∏±‡∏ß
        (‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö component ‡∏ä‡∏∑‡πà‡∏≠‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô‡∏´‡∏•‡∏≤‡∏¢‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á ‡πÄ‡∏ä‡πà‡∏ô screw ‡∏ó‡∏µ‡πà left/center/right)

        Returns:
            List of {
                "component_def_id": int,
                "name": str,
                "position": str,
                "status": "FOUND" or "MISSING",
                "confidence": float,
                "expected_bbox": dict,
                "detected_bbox": dict or None,
                "critical": bool,
                "notes": str
            }
        """

        results = []
        matched_detection_indices = set()  # ‡πÄ‡∏Å‡πá‡∏ö index ‡∏Ç‡∏≠‡∏á detection ‡∏ó‡∏µ‡πà match ‡πÅ‡∏•‡πâ‡∏ß

        for expected in expected_components:
            # ‡∏´‡∏≤ detected object ‡∏ó‡∏µ‡πà match (‡∏¢‡∏Å‡πÄ‡∏ß‡πâ‡∏ô‡∏ó‡∏µ‡πà match ‡πÑ‡∏õ‡πÅ‡∏•‡πâ‡∏ß)
            matched, matched_idx = self._find_matching_object(
                expected,
                mvi_detections,
                matched_detection_indices
            )

            if matched:
                # Mark detection ‡∏ô‡∏µ‡πâ‡∏ß‡πà‡∏≤ match ‡πÅ‡∏•‡πâ‡∏ß
                matched_detection_indices.add(matched_idx)

                results.append({
                    "component_def_id": expected["id"],
                    "name": expected["name"],
                    "position": expected.get("position", ""),
                    "status": "FOUND",
                    "confidence": matched["confidence"],
                    "expected_bbox": expected["roi"],
                    "detected_bbox": matched["bbox"],
                    "critical": expected["critical"],
                    "notes": f"Detected with confidence {matched['confidence']:.2f}"
                })

                if verbose:
                    print(f"  ‚úÖ {expected['name']} ({expected.get('position', 'N/A')}): "
                          f"FOUND (confidence: {matched['confidence']:.2f})")

            else:
                results.append({
                    "component_def_id": expected["id"],
                    "name": expected["name"],
                    "position": expected.get("position", ""),
                    "status": "MISSING",
                    "confidence": 0.0,
                    "expected_bbox": expected["roi"],
                    "detected_bbox": None,
                    "critical": expected["critical"],
                    "notes": "Not detected in expected region"
                })

                if verbose:
                    print(f"  ‚ùå {expected['name']} ({expected.get('position', 'N/A')}): "
                          f"MISSING")

        return results

    def _find_matching_object(self,
                             expected: Dict,
                             detections: List[Dict],
                             matched_indices: set = None) -> Tuple[Optional[Dict], Optional[int]]:
        """
        ‡∏´‡∏≤ detected object ‡∏ó‡∏µ‡πà‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö expected

        ‚ö†Ô∏è ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç: ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö matched_indices ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô detection ‡∏ã‡πâ‡∏≥

        Matching criteria (in order of priority):
        1. Class name ‡∏ï‡πâ‡∏≠‡∏á‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ô (partial match)
        2. IoU > 5% (primary - ‡∏¢‡∏∑‡∏î‡∏´‡∏¢‡∏∏‡πà‡∏ô‡∏Å‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ß‡∏≤‡∏á‡∏ó‡∏µ‡πà‡∏Ñ‡∏•‡∏≤‡∏î‡πÄ‡∏Ñ‡∏•‡∏∑‡πà‡∏≠‡∏ô)
        3. Center distance < tolerance (fallback)

        Args:
            expected: Expected component definition
            detections: List of MVI detections
            matched_indices: Set of detection indices that are already matched

        Returns:
            Tuple of (matched_detection, matched_index) or (None, None)
        """

        if matched_indices is None:
            matched_indices = set()

        expected_center = self._calculate_center(expected["roi"])
        tolerance = expected.get("tolerance", 50)
        min_iou = 0.05  # ‡∏¢‡∏≠‡∏°‡∏£‡∏±‡∏ö‡∏ñ‡πâ‡∏≤‡∏Å‡∏£‡∏≠‡∏ö‡∏ó‡∏±‡∏ö‡∏Å‡∏±‡∏ô‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ô‡πâ‡∏≠‡∏¢ 5% (‡∏¢‡∏∑‡∏î‡∏´‡∏¢‡∏∏‡πà‡∏ô‡∏Å‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ß‡∏≤‡∏á‡∏Ñ‡∏•‡∏≤‡∏î‡πÄ‡∏Ñ‡∏•‡∏∑‡πà‡∏≠‡∏ô)

        best_match = None
        best_match_idx = None
        best_score = 0.0  # IoU score ‡∏´‡∏£‡∏∑‡∏≠ 1/distance

        print(f"\n  üîç Matching '{expected['name']}' at position '{expected.get('position', 'N/A')}':")
        print(f"     Expected: center={expected_center}, size={expected['roi']['width']}x{expected['roi']['height']}")
        print(f"     Matching: IoU>{min_iou*100:.0f}% OR distance<{tolerance}px")
        print(f"     Already matched detections: {matched_indices}")

        for idx, detection in enumerate(detections):
            # ‡∏Ç‡πâ‡∏≤‡∏° detection ‡∏ó‡∏µ‡πà match ‡πÑ‡∏õ‡πÅ‡∏•‡πâ‡∏ß
            if idx in matched_indices:
                print(f"\n     Skipping detection[{idx}]: '{detection['class']}' (already matched)")
                continue

            # ‡πÄ‡∏ä‡πá‡∏Ñ class name (case insensitive + partial match)
            detected_class = detection["class"].lower()
            expected_class = expected["name"].lower()

            print(f"\n     Checking detection[{idx}]: '{detection['class']}' (confidence: {detection['confidence']:.2f})")

            # Check if expected class is contained in detected class or vice versa
            # This handles cases like "Pig Inspection" matching "pig"
            is_match = (expected_class in detected_class or
                       detected_class in expected_class or
                       expected_class == detected_class)

            if not is_match:
                print(f"       ‚ùå Class mismatch: '{detected_class}' !contains '{expected_class}'")
                continue

            print(f"       ‚úì Class match!")

            # Method 1: ‡∏•‡∏≠‡∏á IoU ‡∏Å‡πà‡∏≠‡∏ô (primary)
            iou = self._calculate_iou(expected["roi"], detection["bbox"])
            print(f"       üìê IoU: {iou:.3f} ({iou*100:.1f}%)")

            if iou > min_iou:
                # Match by IoU - ‡∏¢‡∏∑‡∏î‡∏´‡∏¢‡∏∏‡πà‡∏ô‡∏°‡∏≤‡∏Å ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏Å‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ß‡∏≤‡∏á‡∏ó‡∏µ‡πà‡∏Ñ‡∏•‡∏≤‡∏î‡πÄ‡∏Ñ‡∏•‡∏∑‡πà‡∏≠‡∏ô
                if iou > best_score:
                    best_match = detection
                    best_match_idx = idx
                    best_score = iou
                    print(f"       ‚úÖ MATCH by IoU! (best so far: {iou:.3f})")
                continue

            # Method 2: ‡∏•‡∏≠‡∏á center distance (fallback)
            detected_center = self._calculate_center(detection["bbox"])
            distance = self._calculate_distance(expected_center, detected_center)
            print(f"       üìè Center distance: {distance:.1f}px (tolerance: {tolerance}px)")

            if distance <= tolerance:
                # Match by distance
                score = 1.0 / (distance + 1)  # ‡∏¢‡∏¥‡πà‡∏á‡πÉ‡∏Å‡∏•‡πâ‡∏¢‡∏¥‡πà‡∏á‡∏î‡∏µ
                if score > best_score:
                    best_match = detection
                    best_match_idx = idx
                    best_score = score
                    print(f"       ‚úÖ MATCH by distance! (best so far: {distance:.1f}px)")

        if best_match:
            print(f"     ‚úÖ Found best match: detection[{best_match_idx}] = {best_match['class']}")
        else:
            print(f"     ‚ùå No match found (all detections failed IoU and distance check)")

        return best_match, best_match_idx

    def _calculate_center(self, bbox: Dict) -> Tuple[float, float]:
        """‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏à‡∏∏‡∏î‡∏Å‡∏∂‡πà‡∏á‡∏Å‡∏•‡∏≤‡∏á bbox"""
        cx = bbox["x"] + bbox["width"] / 2
        cy = bbox["y"] + bbox["height"] / 2
        return (cx, cy)

    def _calculate_distance(self, point1: Tuple[float, float],
                           point2: Tuple[float, float]) -> float:
        """‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏£‡∏∞‡∏¢‡∏∞‡∏´‡πà‡∏≤‡∏á Euclidean"""
        return np.sqrt((point1[0] - point2[0])**2 + (point1[1] - point2[1])**2)

    def _calculate_iou(self, bbox1: Dict, bbox2: Dict) -> float:
        """‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Intersection over Union (IoU)"""
        x1_min = bbox1["x"]
        y1_min = bbox1["y"]
        x1_max = bbox1["x"] + bbox1["width"]
        y1_max = bbox1["y"] + bbox1["height"]

        x2_min = bbox2["x"]
        y2_min = bbox2["y"]
        x2_max = bbox2["x"] + bbox2["width"]
        y2_max = bbox2["y"] + bbox2["height"]

        # Intersection
        x_inter_min = max(x1_min, x2_min)
        y_inter_min = max(y1_min, y2_min)
        x_inter_max = min(x1_max, x2_max)
        y_inter_max = min(y1_max, y2_max)

        if x_inter_max <= x_inter_min or y_inter_max <= y_inter_min:
            return 0.0

        inter_area = (x_inter_max - x_inter_min) * (y_inter_max - y_inter_min)

        # Union
        bbox1_area = bbox1["width"] * bbox1["height"]
        bbox2_area = bbox2["width"] * bbox2["height"]
        union_area = bbox1_area + bbox2_area - inter_area

        return inter_area / union_area if union_area > 0 else 0.0

    def _analyze_results(self,
                        matching_results: List[Dict],
                        expected_components: List[Dict],
                        verbose: bool = False) -> Dict:
        """‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö"""

        found_count = sum(1 for r in matching_results if r["status"] == "FOUND")
        total_count = len(expected_components)
        found_percentage = (found_count / total_count * 100) if total_count > 0 else 0

        # ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏ó‡∏µ‡πà‡∏´‡∏≤‡∏¢
        missing_components = [
            r["name"]
            for r in matching_results
            if r["status"] == "MISSING"
        ]

        missing_positions = [
            f"{r['name']} ({r['position']})" if r['position'] else r['name']
            for r in matching_results
            if r["status"] == "MISSING"
        ]

        # Critical components ‡∏ó‡∏µ‡πà‡∏´‡∏≤‡∏¢
        missing_critical = [
            r["name"]
            for r in matching_results
            if r["status"] == "MISSING" and r["critical"]
        ]

        # ‡∏ï‡∏±‡∏î‡∏™‡∏¥‡∏ô PASS/FAIL
        if missing_critical:
            status = "FAIL"
            reason = f"Missing critical components: {', '.join(missing_critical)}"
        elif found_count == total_count:
            status = "PASS"
            reason = f"All components found ({found_count}/{total_count})"
        else:
            status = "FAIL"
            reason = f"Found only {found_count}/{total_count} components"

        return {
            "status": status,
            "reason": reason,
            "found_count": found_count,
            "total_count": total_count,
            "found_percentage": found_percentage,
            "missing_components": missing_components,
            "missing_positions": missing_positions
        }

    def _draw_annotations(self,
                         image: np.ndarray,
                         matching_results: List[Dict],
                         expected_components: List[Dict]) -> np.ndarray:
        """
        ‡∏ß‡∏≤‡∏î annotations ‡∏ö‡∏ô‡∏†‡∏≤‡∏û

        - Green box + ‚úì label = FOUND
        - Red box + ‚úó MISSING label = MISSING
        """

        for result in matching_results:
            roi = result["expected_bbox"]

            if result["status"] == "FOUND":
                # ‡∏ß‡∏≤‡∏î‡∏Å‡∏£‡∏≠‡∏ö‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ß + label
                color = (0, 255, 0)  # Green
                label = f"‚úì {result['name']} ({result['confidence']:.2f})"
                thickness = 3
            else:
                # ‡∏ß‡∏≤‡∏î‡∏Å‡∏£‡∏≠‡∏ö‡πÅ‡∏î‡∏á + MISSING
                color = (0, 0, 255)  # Red
                label = f"‚úó {result['name']} MISSING"
                thickness = 4

            # Draw rectangle
            x, y, w, h = roi["x"], roi["y"], roi["width"], roi["height"]
            cv2.rectangle(
                image,
                (x, y),
                (x + w, y + h),
                color,
                thickness
            )

            # Draw filled background for label
            label_size, baseline = cv2.getTextSize(
                label,
                cv2.FONT_HERSHEY_SIMPLEX,
                0.7,
                2
            )

            label_y = y - 10 if y - 10 > label_size[1] else y + h + label_size[1] + 10

            cv2.rectangle(
                image,
                (x, label_y - label_size[1] - 5),
                (x + label_size[0], label_y + baseline),
                color,
                -1
            )

            # Draw label text
            text_color = (255, 255, 255)  # White
            cv2.putText(
                image,
                label,
                (x, label_y - 5),
                cv2.FONT_HERSHEY_SIMPLEX,
                0.7,
                text_color,
                2
            )

            # Draw position label if available
            if result.get("position"):
                position_label = f"[{result['position'].upper()}]"
                cv2.putText(
                    image,
                    position_label,
                    (x, y - 35 if y > 50 else y + h + 40),
                    cv2.FONT_HERSHEY_SIMPLEX,
                    0.6,
                    color,
                    2
                )

        return image

    def parse_mvi_detections_from_image(self, image_path: str) -> List[Dict]:
        """
        Parse MVI detections ‡∏à‡∏≤‡∏Å annotated image
        (‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏£‡∏ì‡∏µ‡∏ó‡∏µ‡πà MVI ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ú‡∏• detection ‡∏•‡∏á‡πÉ‡∏ô‡∏†‡∏≤‡∏û)

        Note: ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏ô‡∏µ‡πâ‡πÄ‡∏õ‡πá‡∏ô placeholder
        ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏à‡∏£‡∏¥‡∏á ‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏ß‡∏£‡πÑ‡∏î‡πâ‡∏£‡∏±‡∏ö detection results ‡πÄ‡∏õ‡πá‡∏ô JSON/dict ‡πÇ‡∏î‡∏¢‡∏ï‡∏£‡∏á
        """
        # TODO: Implement OCR or other method to extract detection from image
        # For now, return empty list
        return []

    def create_comparison_image(self,
                               original_image: np.ndarray,
                               annotated_image: np.ndarray) -> np.ndarray:
        """
        ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏†‡∏≤‡∏û‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö Original vs Annotated

        Returns:
            Side-by-side comparison image
        """
        h1, w1 = original_image.shape[:2]
        h2, w2 = annotated_image.shape[:2]

        # Resize ‡∏ñ‡πâ‡∏≤‡∏Ç‡∏ô‡∏≤‡∏î‡πÑ‡∏°‡πà‡πÄ‡∏ó‡πà‡∏≤‡∏Å‡∏±‡∏ô
        if h1 != h2:
            scale = h1 / h2
            w2 = int(w2 * scale)
            annotated_image = cv2.resize(annotated_image, (w2, h1))

        # Add labels
        cv2.putText(
            original_image,
            "Original",
            (10, 30),
            cv2.FONT_HERSHEY_SIMPLEX,
            1.0,
            (255, 255, 255),
            2
        )

        cv2.putText(
            annotated_image,
            "Analysis Result",
            (10, 30),
            cv2.FONT_HERSHEY_SIMPLEX,
            1.0,
            (255, 255, 255),
            2
        )

        # Concatenate
        comparison = np.hstack([original_image, annotated_image])

        return comparison


# Example usage
if __name__ == "__main__":
    print("MVI Component Integration")
    print("=" * 60)

    from component_definition import ComponentDefinitionManager

    # Initialize
    comp_manager = ComponentDefinitionManager()
    integration = MVIComponentIntegration(comp_manager)

    # Get product
    product = comp_manager.get_product_by_name("Buddha_Set_3pcs")

    if product:
        print(f"\nProduct: {product['name']}")
        print(f"Components: {product.get('component_count', 0)}")

        # Example MVI detections (FAIL case - missing peacock)
        mvi_detections_fail = [
            {
                "class": "pig",
                "confidence": 0.94,
                "bbox": {"x": 178, "y": 180, "width": 182, "height": 268}
            },
            {
                "class": "monk",
                "confidence": 0.98,
                "bbox": {"x": 342, "y": 180, "width": 176, "height": 288}
            }
            # peacock ‡∏´‡∏≤‡∏¢‡πÑ‡∏õ!
        ]

        # Create dummy image
        dummy_image = np.zeros((600, 800, 3), dtype=np.uint8)
        dummy_image[:] = (100, 100, 100)  # Gray background

        # Process
        result = integration.process_mvi_result(
            image=dummy_image,
            mvi_detections=mvi_detections_fail,
            product_id=product['id'],
            verbose=True
        )

        print(f"\nüìä Result Summary:")
        print(f"  Status: {result['status']}")
        print(f"  Reason: {result['reason']}")
        print(f"  Found: {result['found']}/{result['total']} ({result['found_percentage']:.1f}%)")
        print(f"  Missing: {result['missing_components']}")
        print(f"  Missing Positions: {result['missing_positions']}")

        # Example MVI detections (PASS case - all found)
        print("\n" + "=" * 60)
        print("Testing PASS case...")

        mvi_detections_pass = [
            {
                "class": "pig",
                "confidence": 0.90,
                "bbox": {"x": 190, "y": 185, "width": 175, "height": 265}
            },
            {
                "class": "monk",
                "confidence": 0.96,
                "bbox": {"x": 375, "y": 185, "width": 140, "height": 285}
            },
            {
                "class": "peacock",
                "confidence": 0.99,
                "bbox": {"x": 480, "y": 80, "width": 315, "height": 435}
            }
        ]

        result_pass = integration.process_mvi_result(
            image=dummy_image,
            mvi_detections=mvi_detections_pass,
            product_id=product['id'],
            verbose=True
        )

        print(f"\nüìä Result Summary:")
        print(f"  Status: {result_pass['status']}")
        print(f"  Found: {result_pass['found']}/{result_pass['total']}")

    print("\n‚úÖ MVI Component Integration ready!")
